# Free Local LLM Setup Guide (ржмрж╛ржВрж▓рж╛)

## ЁЯЪА ржжрзНрж░рзБржд рж╕рзЗржЯржЖржк (Ollama - Recommended)

### Step 1: Ollama ржЗржирж╕рзНржЯрж▓ ржХрж░рзБржи
1. https://ollama.ai ржерзЗржХрзЗ Ollama ржбрж╛ржЙржирж▓рзЛржб ржХрж░рзБржи
2. Windows/Mac/Linux ржПрж░ ржЬржирзНржп installer ржЪрж╛рж▓рж╛ржи
3. Terminal/Command Prompt ржЦрзБрж▓рзБржи

### Step 2: Model ржбрж╛ржЙржирж▓рзЛржб ржХрж░рзБржи
```bash
# Fast ржПржмржВ ржнрж╛рж▓ quality ржПрж░ ржЬржирзНржп (Recommended)
ollama pull llama3.2

# ржЕржержмрж╛ ржЖрж░рзЛ ржЫрзЛржЯ model (ржжрзНрж░рзБржд ржХрж┐ржирзНрждрзБ ржХржо quality)
ollama pull mistral

# ржЕржержмрж╛ ржЖрж░рзЛ ржнрж╛рж▓ quality (ржзрзАрж░ ржХрж┐ржирзНрждрзБ ржнрж╛рж▓)
ollama pull llama3
```

### Step 3: .env ржлрж╛ржЗрж▓рзЗ ржпрзЛржЧ ржХрж░рзБржи
`.env` ржлрж╛ржЗрж▓рзЗ ржПржЗ рж▓рж╛ржЗржиржЧрзБрж▓рзЛ ржпрзЛржЧ ржХрж░рзБржи:
```
USE_LOCAL_LLM=true
LOCAL_LLM_TYPE=ollama
LOCAL_LLM_MODEL=llama3.2
USE_FREE_EMBEDDINGS=true
```

### Step 4: App Restart ржХрж░рзБржи
Streamlit app restart ржХрж░рзБржи ржПржмржВ test ржХрж░рзБржи!

## ЁЯУК Model Comparison

| Model | Size | Speed | Quality | Command |
|-------|------|-------|---------|---------|
| llama3.2 | ~2GB | тЪбтЪбтЪб Fast | тнРтнРтнР Good | `ollama pull llama3.2` |
| mistral | ~4GB | тЪбтЪб Fast | тнРтнРтнРтнР Very Good | `ollama pull mistral` |
| llama3 | ~4.7GB | тЪб Medium | тнРтнРтнРтнРтнР Excellent | `ollama pull llama3` |

## ЁЯФз Alternative: HuggingFace Models

ржпржжрж┐ Ollama ржХрж╛ржЬ ржирж╛ ржХрж░рзЗ, HuggingFace ржмрзНржпржмрж╣рж╛рж░ ржХрж░рждрзЗ ржкрж╛рж░рзЗржи:

### .env ржлрж╛ржЗрж▓рзЗ:
```
USE_LOCAL_LLM=true
LOCAL_LLM_TYPE=huggingface
LOCAL_LLM_MODEL=microsoft/DialoGPT-medium
USE_FREE_EMBEDDINGS=true
```

### Install dependencies:
```bash
pip install transformers accelerate
```

## тЬЕ Benefits

- тЬЕ **100% FREE** - ржХрзЛржирзЛ API key рж▓рж╛ржЧржмрзЗ ржирж╛
- тЬЕ **Fast** - Local ржП run ржХрж░рзЗ рждрж╛ржЗ ржжрзНрж░рзБржд
- тЬЕ **Private** - ржЖржкржирж╛рж░ data ржХржЦржирзЛ internet ржП ржпрж╛ржмрзЗ ржирж╛
- тЬЕ **No Quota** - Unlimited use

## ЁЯОп Recommended Settings

рж╕ржмржЪрзЗржпрж╝рзЗ ржнрж╛рж▓ performance ржПрж░ ржЬржирзНржп `.env` ржлрж╛ржЗрж▓рзЗ:
```
USE_LOCAL_LLM=true
LOCAL_LLM_TYPE=ollama
LOCAL_LLM_MODEL=llama3.2
USE_FREE_EMBEDDINGS=true
```

ржПржЦржи ржЖржкржирж╛рж░ app рж╕ржорзНржкрзВрж░рзНржг free ржПржмржВ fast рж╣ржмрзЗ! ЁЯЪА

